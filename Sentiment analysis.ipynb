{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Movie reviews sentiment analysis challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Sentiment Analysis is the most common text classification tool that analyses an incoming message and tells whether the underlying sentiment is positive, negative or neutral. You can input a sentence of your choice and gauge the underlying sentiment by playing with the demo [here](https://www.paralleldots.com/sentiment-analysis).\n",
    "\n",
    "We have a dataset which has a couple of columns, one of them being a review (or the description). The idea is to determine the sentiment from the review text. Essentially, that would consist of figuring out how positive or negative the sentiment is. Which means, this would be more or less of a regression problem than a classification one. \n",
    "\n",
    "\n",
    "There are 2 files, a `train.tsv` and a `test.tsv`. We will train our models on the `train.tsv` dataset. First we will split the `train.tsv` dataset into training data and testing data to determine the model accuracy, take the best model and then test it on our `test.tsv`. It will be imperative to combine both train and test tsvs onto a single file, just for the purpose of Vectorizing them. The model will not be trained on the complete set!!\n",
    "\n",
    "\n",
    "# About the dataset\n",
    "\n",
    "\n",
    "The snapshot of the data you will be working on:\n",
    "\n",
    "<img src=\"movie.png\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Why solve it ?\n",
    "\n",
    "Solving it will help you apply the following skills:\n",
    "\n",
    "- Text preprocessing techniques like\n",
    "    - Tokenization \n",
    "    - Stopword removal\n",
    "    - Count vectorizer\n",
    "    - Tf-idf vectorizer\n",
    "\n",
    "- Implementation of \n",
    "    - Random forest\n",
    "    - Naive Bayes\n",
    "    - Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess the data\n",
    "\n",
    "Transforming text into something an algorithm can digest it a complicated process. We cannot feed the data as it is, some preprocessing needs to be done. In this task we will be doing some preprocessing to convert our data in a form that we can feed our model with.\n",
    "\n",
    "## Instructions\n",
    "* Load the data which is in a `.tsv` format and convert it to a dataframe using `pd.DataFrame.from_csv()` with parameters `path=path_train` and `sep=\"\\t\"` for training data and store it in a variable `df_train`. Similarly load the test data and store it in a variable `df_test`\n",
    "\n",
    "* Concat the column `Phrase` from `df_train` and `df_test` data and store it in a new dataframe `phrases`\n",
    "\n",
    "* Convert the `Phrase` column to lower case and assign it to a pandas series called `all_text`\n",
    "\n",
    "## Hints\n",
    "* Use `phrases = pd.concat([df_train[[\"Phrase\"]], df_test[[\"Phrase\"]]])` to concat the `Phrase` column from train and test dataframe\n",
    "\n",
    "## Test case\n",
    "* Variable declration `df_train`,`df_test`,`phrases` and `all_text`\n",
    "    - df_train.shape==(156060, 3)\n",
    "    - df_test.shape==(66292, 2)\n",
    "    - phrases.Phrase[5]=='series'\n",
    "    - all_text[7]=='of'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\Ali & Alifia's Home\\Downloads\\movie-review-sentiment-analysis\\movie-review-sentiment-analysis\\data\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "# Load the training data\n",
    "df_train = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Load the testing data\n",
    "df_test = pd.read_csv(\"test.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Concat the 'Phrases' column from train and test dataset\n",
    "phrases = pd.concat([df_train[[\"Phrase\"]], df_test[[\"Phrase\"]]])\n",
    "\n",
    "# Shape of the new dataframe\n",
    "print (phrases.shape[0]==(df_train.shape[0]+df_test.shape[0]))\n",
    "\n",
    "# Convert all the phrases to lower case\n",
    "all_text = phrases[\"Phrase\"].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer\n",
    "Apart from Count vectorizer an alternative to calculate word frequencies , and by far the most popular method is called TF-IDF. This is an acronym than stands for “Term Frequency – Inverse Document” Frequency which are the components of the resulting scores assigned to each word.\n",
    "\n",
    "    * Term Frequency: This summarizes how often a given word appears within a document.\n",
    "    * Inverse Document Frequency: This downscales words that appear a lot across documents.\n",
    "\n",
    "TF-IDF are word frequency scores that try to highlight words that are more interesting, e.g. frequent in a document but not across documents.\n",
    "\n",
    "## Instructions\n",
    "* Instantiate `TfidfVectorizer(stop_words=\"english\")` and store it in a variable `tfidf`\n",
    "\n",
    "* Fit `tfidf` on `all_text` data\n",
    "\n",
    "* Transform `all_text` data using `tfidf` and store it in a variable `X`\n",
    "\n",
    "* Store data upto index 156060 in a variable `X_train` and the data after index 156060 in a variable `X_test`\n",
    "\n",
    "* Store the `Sentiment` column from `df_train` in a variable `y`\n",
    "\n",
    "* Split the train data into `X_train_train`, `X_train_test`,`y_train_train` and `y_train_test` and pass the parameters as `X_train`,`y`,`test_size`=0.3 and `random_state = 42`\n",
    "\n",
    "## Hints\n",
    "* Use `tfidf.transform(all_text).toarray()` to convert the vectorizer result to an array\n",
    "\n",
    "* Use `X_train_train, X_train_test, y_train_train, y_train_test = tts(X_train,y,test_size=0.3, random_state=42)` to split the training data into train and test part.\n",
    "\n",
    "## Test case\n",
    "\n",
    "Variable declaration `tfidf`,`X`,`y`,`X_train_train`,`X_train_test`,`y_train_train`,`y_train_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Code starts here\n",
    "# TF-IDF vectorize all text after removing the 'stopwords'\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf.fit(all_text)\n",
    "\n",
    "# Vectorizer result to an array\n",
    "X = tfidf.transform(all_text)\n",
    "# Train and test data\n",
    "X_train= X[:156060]\n",
    "X_test = X[156060:]\n",
    "\n",
    "# New column 'y' assigned with the `sentiment` column from training data\n",
    "y = df_train[\"Sentiment\"]\n",
    "\n",
    "# X_train and y shape match\n",
    "print (X_train.shape[0]==y.shape[0])\n",
    "\n",
    "# Dividing the train data into training and testing data\n",
    "X_train_train, X_train_test, y_train_train, y_train_test = train_test_split(X_train,y,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB accuracy: 0.6064334230424195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "# Instantiate NB classifier\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Fit the NB classifier on train and test data\n",
    "nb.fit(X_train_train,y_train_train)\n",
    "\n",
    "# Predictions of the test data\n",
    "y_pred = nb.predict(X_train_test)\n",
    "\n",
    "# Accuracy of the model\n",
    "nb_accuracy = accuracy_score(y_train_test,y_pred)\n",
    "print(\"Multinomial NB accuracy:\", nb_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "SVC accuracy: 0.6294160365671323\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "# Code starts here\n",
    "\n",
    "# Instantiate Count vectorizer\n",
    "cv = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Fit the data on count vectorizer\n",
    "cv.fit(all_text)\n",
    "\n",
    "# Vectorizer result to an array\n",
    "X = cv.transform(all_text)\n",
    "\n",
    "# Train and test data\n",
    "X_train= X[:156060]\n",
    "X_test = X[156060:]\n",
    "print (X_train.shape[0]==y.shape[0])\n",
    "\n",
    "# Split the data into train and test data\n",
    "X_train_train, X_train_test, y_train_train, y_train_test = train_test_split(X_train,y,test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit NB classifier on train data\n",
    "nb.fit(X_train_train,y_train_train)\n",
    "\n",
    "# Predicted result of test data using NB classifier\n",
    "y_pred_nb = nb.predict(X_train_test)\n",
    "\n",
    "# Accuracy of model\n",
    "nb_accuracy = accuracy_score(y_train_test,y_pred_nb)\n",
    "\n",
    "# Instantiate the LinearSVC() model\n",
    "svc = LinearSVC()\n",
    "\n",
    "# Fit svc classifier on train data\n",
    "model = svc.fit(X_train_train,y_train_train)\n",
    "\n",
    "# Predicted result of test data using svc\n",
    "y_pred_svc = model.predict(X_train_test)\n",
    "\n",
    "# Accuracy model\n",
    "svc_accuracy = accuracy_score(y_train_test,y_pred_svc)\n",
    "print(\"SVC accuracy:\", svc_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66287</th>\n",
       "      <td>222348</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66288</th>\n",
       "      <td>222349</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66289</th>\n",
       "      <td>222350</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded ,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66290</th>\n",
       "      <td>222351</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66291</th>\n",
       "      <td>222352</td>\n",
       "      <td>11855</td>\n",
       "      <td>predictable scenario</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66292 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PhraseId  SentenceId  \\\n",
       "0        156061        8545   \n",
       "1        156062        8545   \n",
       "2        156063        8545   \n",
       "3        156064        8545   \n",
       "4        156065        8545   \n",
       "...         ...         ...   \n",
       "66287    222348       11855   \n",
       "66288    222349       11855   \n",
       "66289    222350       11855   \n",
       "66290    222351       11855   \n",
       "66291    222352       11855   \n",
       "\n",
       "                                                  Phrase  predicted_sentiment  \n",
       "0      An intermittently pleasing but mostly routine ...                    3  \n",
       "1      An intermittently pleasing but mostly routine ...                    3  \n",
       "2                                                     An                    2  \n",
       "3      intermittently pleasing but mostly routine effort                    3  \n",
       "4             intermittently pleasing but mostly routine                    3  \n",
       "...                                                  ...                  ...  \n",
       "66287             A long-winded , predictable scenario .                    1  \n",
       "66288               A long-winded , predictable scenario                    1  \n",
       "66289                                    A long-winded ,                    1  \n",
       "66290                                      A long-winded                    1  \n",
       "66291                               predictable scenario                    2  \n",
       "\n",
       "[66292 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the best model on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Append a column 'predicted_sentiment' to the test data\n",
    "df_test[\"predicted_sentiment\"] = y_pred\n",
    "\n",
    "# Convert your dataframe into an excel sheet and save it\n",
    "df_test.to_csv(\"Predicted sentiments.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
